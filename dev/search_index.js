var documenterSearchIndex = {"docs":
[{"location":"custom/#Customizing-your-sampler","page":"Customizing your sampler","title":"Customizing your sampler","text":"","category":"section"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"This document describes how to extend DEMetropolis.jl with your own custom components. You can define custom stopping criteria, diagnostic checks, and proposal distributions (updates).","category":"page"},{"location":"custom/#Custom-Stopping-Criteria","page":"Customizing your sampler","title":"Custom Stopping Criteria","text":"","category":"section"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"To create a custom stopping criterion, you need to define a new struct that is a subtype of DEMetropolis.stopping_criteria_struct and then implement the DEMetropolis.stop_sampling method for your new type.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"The stop_sampling method has the following signature: stop_sampling(stopping_criteria::YourCriteria, chains::chains_struct, sample_from::Int, last_iteration::Int)","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"stopping_criteria: An instance of your custom stopping criterion struct.\nchains: The chains_struct containing the state of all chains. You can use DEMetropolis.population_to_samples to extract samples.\nsample_from: The iteration number at which sampling (post-warmup) began.\nlast_iteration: The total number of iterations completed so far (per chain).","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"The function should return true if sampling should stop, and false otherwise.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"Here is an example of a stopping criterion that stops sampling after a maximum number of iterations has been reached.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"using DEMetropolis\n\n# Define the struct for the stopping criterion\nstruct MaxIterationsStopping <: DEMetropolis.stopping_criteria_struct\n    max_iters::Int\nend\n\n# Implement the stop_sampling function\nfunction DEMetropolis.stop_sampling(criterion::MaxIterationsStopping, chains, sample_from, last_iteration)\n    if length(DEMetropolis.get_sampling_indices(sample_from, last_iteration)) >= criterion.max_iters\n        println(\"Reached maximum iterations, stopping.\")\n        return true\n    end\n    return false\nend","category":"page"},{"location":"custom/#Custom-Diagnostic-Checks","page":"Customizing your sampler","title":"Custom Diagnostic Checks","text":"","category":"section"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"You can implement custom diagnostic checks that are run during the warmup/burn-in phase. This is useful for monitoring chain behavior and potentially correcting issues on the fly, like resetting outlier chains.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"To create a custom diagnostic, define a struct that subtypes DEMetropolis.diagnostic_check_struct and implement DEMetropolis.run_diagnostic_check! for it.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"The method signature is: run_diagnostic_check!(chains, diagnostic_check::YourCheck, rngs, current_iteration::Int)","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"chains: The chains_struct, which can be modified within the function.\ndiagnostic_check: An instance of your custom diagnostic struct.\nrngs: A vector of random number generators, one for each chain.\ncurrent_iteration: The current warmup iteration number.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"Here is an example of a simple diagnostic that just prints a message. A more advanced check could, for example, calculate acceptance rates and reset chains that are not mixing well.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"using DEMetropolis\n\n# Define the struct for the diagnostic check\nstruct MyCustomDiagnostic <: DEMetropolis.diagnostic_check_struct\n    bad_number::Float64\nend\n\n# Implement the run_diagnostic_check! function\nfunction DEMetropolis.run_diagnostic_check!(chains, check::MyCustomDiagnostic, rngs, current_iteration)\n    println(\"Running custom diagnostic at warmup iteration: \", current_iteration)\n    # This is where you would add logic to inspect and modify chains\n\n    # As an example we'll resample all chains that include a bad number (since these are floats it'll probably never happen)\n    X = DEMetropolis.population_to_samples(chains, DEMetropolis.get_sampling_indices(1, current_iteration))\n    \n    chains = 1:chains.n_chains;\n\n    outliers = setdiff([findfirst(check.bad_number .== X[:, chain, :]) for chain in chains], [nothing]);\n    fine_chains = setdiff(chains, outliers);\n\n    if length(outliers) > 0\n        @warn string(length(outliers)) * \" outlier chains detected, setting to random chains\"\n\n        resampled = [rand(rngs[outlier], fine_chains) for outlier in outliers];\n\n        chains.ld[chains.current_position[outliers], :] .= chains.ld[chains.current_position[resampled], :];\n        chains.X[chains.current_position[outliers], :] .= chains.X[chains.current_position[resampled], :];\n    end\nend","category":"page"},{"location":"custom/#Custom-Proposal-Distributions","page":"Customizing your sampler","title":"Custom Proposal Distributions","text":"","category":"section"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"The core of the samplers in DEMetropolis.jl are the update steps, which propose new parameter values. You can create your own proposal distributions by defining a new update type.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"To do this, create a struct that subtypes DEMetropolis.update_struct and implement the DEMetropolis.update! method for it.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"The method signature for the update is: update!(update::YourUpdate, chains, ld, rng, chain::Int)","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"update: An instance of your custom update struct.\nchains: The chains_struct. Helper functions like DEMetropolis.get_value and DEMetropolis.update_value! are available to get the current state and to update it after the Metropolis-Hastings step.\nld: The log-density function from LogDensityProblems.jl.\nrng: The random number generator for the current chain.\nchain: The index of the chain to be updated.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"If your proposal distribution requires adaptation (e.g., tuning a step size during warmup), you can also implement DEMetropolis.adapt_update!(update::YourUpdate, chains).","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"Here is an example of a simple Metropolis-Hastings random walk update with a fixed step size.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"using DEMetropolis, LogDensityProblems, Distributions, LinearAlgebra\n\n# Define the struct for the update\nstruct MetropolisHastingsUpdate <: DEMetropolis.update_struct\n    proposal_distribution::MvNormal\nend\n# Implement the update! function\nfunction DEMetropolis.update!(update::MetropolisHastingsUpdate, chains, ld, rng, chain)\n    # Get the current state of the chain\n    x_current = DEMetropolis.get_value(chains, chain)\n    \n    # Propose a new point using a random walk\n    x_proposal = x_current .+ rand(rng, update.proposal_distribution);\n    \n    # Calculate the log-density of the proposed point\n    ld_proposal = LogDensityProblems.logdensity(ld, x_proposal)\n    \n    # The proposal is symmetric, so the Hastings factor is 0 in log-space. Other this could be included via offset = ...\n    # update_value! handles the acceptance/rejection step.\n    DEMetropolis.update_value!(chains, rng, chain, x_proposal, ld_proposal)\nend","category":"page"},{"location":"custom/#Adaptive-Metropolis-Hastings-Update","page":"Customizing your sampler","title":"Adaptive Metropolis-Hastings Update","text":"","category":"section"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"For more complex problems, an adaptive proposal can be much more efficient. The following example shows how to create a Metropolis-Hastings update that adapts its proposal distribution during the warmup phase. It uses the covariance of the samples drawn so far to shape the proposal, which is a common technique in adaptive MCMC.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"To achieve this, we will implement the DEMetropolis.adapt_update! method, which is called periodically during the sampling process.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"using DEMetropolis, LogDensityProblems, Distributions, LinearAlgebra, Statistics\n\n# The struct needs to be mutable to allow the proposal distribution to be updated.\nmutable struct AdaptiveMetropolisUpdate <: DEMetropolis.update_struct\n    proposal_distribution::MvNormal\n    # Parameters to control the adaptation\n    adapt_after::Int  # Start adapting after this many iterations\n    adapt_every::Int  # Adapt every N iterations\n    adapt_scale::Float64 # Scale factor for the covariance\nend\n\n# A constructor to set up the initial state\nfunction AdaptiveMetropolisUpdate(\n    n_pars::Int;\n    initial_std::Float64=0.1,\n    adapt_after::Int=200,\n    adapt_every::Int=100,\n    adapt_scale::Float64=2.38^2\n)\n    # Start with a simple isotropic proposal\n    initial_cov = (initial_std^2) * I(n_pars)\n    proposal = MvNormal(zeros(n_pars), initial_cov)\n    return AdaptiveMetropolisUpdate(proposal, adapt_after, adapt_every, adapt_scale / n_pars)\nend\n\n# The update! method is the same as for the non-adaptive version\nfunction DEMetropolis.update!(update::AdaptiveMetropolisUpdate, chains, ld, rng, chain)\n    x_current = DEMetropolis.get_value(chains, chain)\n    # Propose a new point using the current proposal distribution\n    x_proposal = x_current .+ rand(rng, update.proposal_distribution)\n    ld_proposal = LogDensityProblems.logdensity(ld, x_proposal)\n    DEMetropolis.update_value!(chains, rng, chain, x_proposal, ld_proposal)\nend\n\n# The adapt_update! method contains the adaptation logic\nfunction DEMetropolis.adapt_update!(update::AdaptiveMetropolisUpdate, chains)\n    # Only adapt during warmup, after a burn-in period, and at specified intervals\n    if !chains.warmup || chains.samples < update.adapt_after || chains.samples % update.adapt_every != 0\n        return\n    end\n\n    println(\"Adapting proposal at iteration \", chains.samples)\n\n    # Get all the warmup samples up to the current point\n    warmup_samples_3d = DEMetropolis.population_to_samples(chains, 1:(chains.samples-1))\n    \n    # Reshape to a 2D matrix (n_samples, n_params)\n    n_params = size(warmup_samples_3d, 3)\n    warmup_samples_2d = reshape(warmup_samples_3d, :, n_params)\n\n    # Calculate the covariance of the samples and regularize it\n    cov_matrix = cov(warmup_samples_2d)\n    regularized_cov = cov_matrix + 1e-6 * I\n\n    # Update the proposal distribution\n    update.proposal_distribution = MvNormal(zeros(n_params), update.adapt_scale .* regularized_cov)\nend","category":"page"},{"location":"custom/#Example:-Using-Custom-Components","page":"Customizing your sampler","title":"Example: Using Custom Components","text":"","category":"section"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"Here is a complete example that shows how to use all the custom components defined above with composite_sampler.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"using DEMetropolis, LogDensityProblems, TransformVariables, Distributions, TransformedLogDensities\n\n# Set up and run the sampler\n\n# A simple log-density to sample from (a 2D standard normal distribution)\nld = TransformedLogDensity(as(Array, 2), x -> -sum(x.^2) / 2);\n\n# Use our custom Metropolis-Hastings update\nmy_sampler_scheme = setup_sampler_scheme(\n    MetropolisHastingsUpdate(MvNormal([0.0, 0.0], I)), AdaptiveMetropolisUpdate(2)\n);\n\n# Use our custom stopping criterion\nmy_stopping_criterion = MaxIterationsStopping(2000);\n\n# Use our custom diagnostic check\nmy_diagnostics = [MyCustomDiagnostic(-100.0)];\n\n# Set up initial state for the chains (10 chains for a 2-parameter model)\n# For memoryless sampling, the number of rows is the number of chains.\ninitial_state = randn(10, 2);\n\n# Run the composite sampler with all our custom components\n# epoch_size is the number of samples per chain, per epoch\noutput = composite_sampler(\n    ld,\n    1000, \n    10,\n    false, # memoryless\n    initial_state,\n    my_sampler_scheme,\n    my_stopping_criterion;\n    warmup_epochs = 5,\n    diagnostic_checks = my_diagnostics\n);\n\nprintln(\"Sampling finished. Total samples per chain: \", size(output.samples, 1))\nprintln(\"Adapted Covariance: \", output.sampler_scheme.updates[2].proposal_distribution.Σ)","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"This will print the median and 90% credible interval for each parameter, giving you a summary of the posterior distribution.","category":"page"},{"location":"custom/","page":"Customizing your sampler","title":"Customizing your sampler","text":"For more details, see the DEMetropolis Documentation and the Customizing your sampler section. For general Julia documentation and best practices, refer to the Julia documentation manual.","category":"page"},{"location":"#DEMetropolis-Documentation","page":"DEMetropolis Documentation","title":"DEMetropolis Documentation","text":"","category":"section"},{"location":"","page":"DEMetropolis Documentation","title":"DEMetropolis Documentation","text":"Tools for sampling from log-densities using differential evolution algorithms.","category":"page"},{"location":"","page":"DEMetropolis Documentation","title":"DEMetropolis Documentation","text":"See Sampling from multimodal distributions and Customizing your sampler to get started.","category":"page"},{"location":"","page":"DEMetropolis Documentation","title":"DEMetropolis Documentation","text":"This package is built upon LogDensityProblems.jl so log-densities should be constructed using that package, and can be used with TransformVariables.jl to control the parameter space.","category":"page"},{"location":"","page":"DEMetropolis Documentation","title":"DEMetropolis Documentation","text":"The other key dependency is Distributions.jl. Almost every parameter in proposals given here (see Proposal Distributions) are defined via customizable univariate distributions. Values that are fixed are specified via a Dirac distribution, though in the API these can be specified with any real value. As a warning there are minimal checks on the given distributions, it is up to the user to ensure that they are suitable for the given parameter, i.e. there is nothing stopping you from having the noise term in the deMC proposal be centred around 100 instead of 0, or have the distribution for a probability be > 1. Distributions can optionally be used to define your log-density, as in the examples given here. ","category":"page"},{"location":"","page":"DEMetropolis Documentation","title":"DEMetropolis Documentation","text":"As far as I am aware, there is one other package that implements differential evolution MCMC in Julia, DifferentialEvolutionMCMC.jl. I opted to implement my own version as I wanted a more flexible API and the subsampling scheme from DREAM. That's not to discredit DifferentialEvolutionMCMC.jl, it has many features this package does not, such as being able to work on optimization problems and parameter blocking.","category":"page"},{"location":"#Next-Steps","page":"DEMetropolis Documentation","title":"Next Steps","text":"","category":"section"},{"location":"","page":"DEMetropolis Documentation","title":"DEMetropolis Documentation","text":"A few plans for this package, feel free to suggest features or improvements via issues:","category":"page"},{"location":"","page":"DEMetropolis Documentation","title":"DEMetropolis Documentation","text":"Implement multi-try and delayed rejection DREAM, I avoided these so far since I have been using these samplers for costly log-densities with relatively few parameters, such as one that solve an ODE.\nIntegrate with AbstractMCMC and MCMCChains, potentially not worth the cost since parrallelism in a deMCMC is within chains rather than across chains.","category":"page"},{"location":"#Contents","page":"DEMetropolis Documentation","title":"Contents","text":"","category":"section"},{"location":"","page":"DEMetropolis Documentation","title":"DEMetropolis Documentation","text":"","category":"page"},{"location":"#Functions","page":"DEMetropolis Documentation","title":"Functions","text":"","category":"section"},{"location":"#Implemented-Sampling-Schemes","page":"DEMetropolis Documentation","title":"Implemented Sampling Schemes","text":"","category":"section"},{"location":"#DEMetropolis.deMC","page":"DEMetropolis Documentation","title":"DEMetropolis.deMC","text":"Run the Differential Evolution Markov Chain (DE-MC) sampler proposed by ter Braak (2006)\n\nThis sampler uses the de_update step. It can optionally switch between two γ values (γ₁ and γ₂) with probability p_γ₂. This is so that the sampler can occasionally move between modes, by having γ₂ = 1 while γ₁ remains the optimal value based on the dimension of the problem.\n\nThis algorithm varies slightly from the original. Updates within a population occur on the previous position of that population. i.e. if chain 1 has been updated (a₁ → a₂) and chain 2 picks chain 1 to update from, then the value of chain 1 used by chain 2 is the pre-update version of chain 1 (a₁). This change allows the algorithm to be easily parallelised.\n\nSee doi.org/10.1007/s11222-006-8769-1 for more information on sampler.\n\nArguments\n\nld: The log-density function to sample from, intended to be a LogDensityProblem.\nn_its: The number of sampling iterations per chain.\n\nKeyword Arguments\n\nn_burnin: Number of burn-in iterations. Defaults to n_its * 5.\nn_chains: Number of chains. Defaults to dimension(ld) * 2.\ninitial_state: Initial states for the chains. Defaults to randn(rng, n_chains, dimension(ld)).\nN₀: Size of the initial population (must be >= nchains + 3), only used if using memory-based sampling. Defaults to `nchains * 2`.\nmemory: Use memory-based sampling (true) or memoryless (false). Defaults to false.\nsave_burnt: Save burn-in samples. Defaults to false.\nparallel: Run chains in parallel. Defaults to false.\nrng: Random number generator. Defaults to default_rng().\ndiagnostic_checks: Diagnostic checks to run during burn-in. Defaults to nothing.\ncheck_epochs: Splits n_burnin into check_epochs + 1 epochs and applies the diagnostic checks at the end of each epoch, other than the final epoch. Defaults to 1.\nthin: Thinning interval. Defaults to 1.\nγ₁: Primary scaling factor for DE update. Defaults to 2.38 / sqrt(2 * dim).\nγ₂: Secondary scaling factor for DE update. Defaults to 1.0.\np_γ₂: Probability of using γ₂. Defaults to 0.1.\nβ: Noise distribution for DE update. Defaults to Uniform(-1e-4, 1e-4).\n\nReturns\n\nA named tuple containing the samples, sampler scheme, and potentially burn-in samples.\n\nExample\n\njulia> deMC(ld, 1000; n_chains = 10)\n\nSee also composite_sampler, deMCzs, DREAMz.\n\n\n\n\n\n","category":"function"},{"location":"#DEMetropolis.deMCzs","page":"DEMetropolis Documentation","title":"DEMetropolis.deMCzs","text":"Run the Differential Evolution Markov Chain with snooker update and historic sampling (DE-MCzs) sampler proposed by ter Braak and Vrugt (2008).\n\nThis sampler runs until a stopping_criteria (default: Rhat of the last 50% of the chains is <1.2) is met. The sampler can occasionally propose snooker updates which can sample areas away from the current chains. Combined with the adaptive memory-based sampling this sampler can efficiently sample from a problem where n_chains < the dimension of the problem.\n\nSee: doi.org/10.1007/s11222-008-9104-9 for more information\n\nArguments\n\nld: The log-density function to sample from, intended to be a LogDensityProblem.\nepoch_size: The number of saved iterations per chain per epoch.\n\nKeyword Arguments\n\nwarmup_epochs: Number of warm-up epochs. Defaults to 5.\nepoch_limit: Maximum number of sampling epochs. Defaults to 20.\nn_chains: Number of chains. Defaults to dimension(ld) * 2.\nN₀: Size of the initial population (must be >= nchains + 3). Defaults to `nchains * 2`.\ninitial_state: Initial population state. Defaults to randn(rng, N₀, dimension(ld)).\nmemory: Use memory based sampling? Defaults to true.\nsave_burnt: Save warm-up samples. Defaults to true.\nparallel: Run chains in parallel with multithreading. Defaults to false.\nrng: Random number generator. Defaults to default_rng().\ndiagnostic_checks: Diagnostic checks during warm-up. Defaults to nothing.\nstopping_criteria: Criterion to stop sampling. Defaults to R̂_stopping_criteria().\nγ: Scaling factor for the DE update. Defaults to 2.38 / sqrt(2 * dim).\nγₛ: Scaling factor for the Snooker update. Defaults to 2.38 / sqrt(2).\np_snooker: Probability of using the Snooker update. Defaults to 0.1.\nβ: Noise distribution for DE update. Defaults to Uniform(-1e-4, 1e-4).\nthin: Thinning interval. Defaults to 10.\n\nReturns\n\nA named tuple containing the samples, sampler scheme, and potentially burn-in samples.\n\nExample\n\njulia> deMCzs(ld, 1000; n_chains = 3)\n\nSee also composite_sampler, deMC, DREAMz.\n\n\n\n\n\n","category":"function"},{"location":"#DEMetropolis.DREAMz","page":"DEMetropolis Documentation","title":"DEMetropolis.DREAMz","text":"Run the Differential Evolution Adaptive Metropolis (DREAMz) sampler\n\nThis sampler runs until a stopping_criteria (default: Rhat of the last 50% of the chains is <1.2) is met. The sampler uses subspace_sampling, where the cross-over probability is adapted during the burn-in period. It can optionally switch between two γ values, so that γ₁ can be the optimal value (based on sampled parameters) and γ₂ can be some fixed value (i.e. 1) so that the sampler can switch modes. This sampler also checks for outlier chains (where the mean log-density falls outside the IQR) and replaces then with the position of the chain with the highest log-density. This step breaks detailed balance its not performed in the last epoch of the warm-up period.\n\nBy default this is a memory-based sampler (DREAMz). Setting memory = false makes this the DREAM sampler.\n\nSee doi.org/10.1515/IJNSNS.2009.10.3.273 for more info.\n\nArguments\n\nld: The log-density function to sample from, intended to be a LogDensityProblem.\nepoch_size: The number of saved iterations per chain per epoch.\n\nKeyword Arguments\n\nwarmup_epochs: Number of warm-up epochs. Defaults to 5. Crossover probabilities are adapted in this period.\nepoch_limit: Maximum number of sampling epochs. Defaults to 20.\nn_chains: Number of chains. Defaults to dimension(ld) * 2.\nN₀: Size of the initial population (must be >= nchains). Defaults to `nchains. Only the firstn_chainswill be used ifmemory = false`.\ninitial_state: Initial population state. Defaults to randn(rng, N₀, dimension(ld)).\nmemory: Use memory-based sampling (true) or memoryless (false). Defaults to true.\nsave_burnt: Save warm-up samples. Defaults to true.\nparallel: Run chains in parallel. Defaults to false.\nrng: Random number generator. Defaults to default_rng().\ndiagnostic_checks: Diagnostic checks during warm-up. Defaults to [ld_check()].\nstopping_criteria: Criterion to stop sampling. Defaults to R̂_stopping_criteria().\nγ₁: Primary scaling factor for subspace update. Defaults to nothing (uses 2.38 / sqrt(2 * δ * d)). Can also be a Real value.\nγ₂: Secondary scaling factor for subspace update. Defaults to 1.0. Can also be a Real value\np_γ₂: Probability of using γ₂. Defaults to 0.2.\nn_cr: Number of crossover probabilities to adapt if cr₁/cr₂ are nothing. Defaults to 3.\ncr₁: Crossover probability distribution/value for γ₁. Defaults to nothing (adaptive). Can also be a Real value (<1) or a Distributions.UnivariateDistribution, in either case it is not adapted.\ncr₂: Crossover probability distribution/value for γ₂. See above.\nϵ: Additive noise distribution. Defaults to Uniform(-1e-4, 1e-4).\ne: Multiplicative noise distribution. Defaults to Normal(0.0, 1e-2).\nδ: Number of difference vectors distribution. Defaults to DiscreteUniform(1, 3).\nthin: Thinning interval. Defaults to 1.\n\nReturns\n\nA named tuple containing the samples, sampler scheme, and potentially burn-in samples.\n\nExample\n\njulia> DREAMz(ld, 1000; n_chains = 10)\n\nSee also composite_sampler, deMC, deMCzs.\n\n\n\n\n\n","category":"function"},{"location":"#Tools-for-setting-up-your-own-sampler","page":"DEMetropolis Documentation","title":"Tools for setting up your own sampler","text":"","category":"section"},{"location":"#DEMetropolis.setup_sampler_scheme","page":"DEMetropolis Documentation","title":"DEMetropolis.setup_sampler_scheme","text":"Create a sampler scheme defining the update steps to be used in composite_sampler.\n\nThe update used in each iteration for each chain is randomly selected from the updates given here.\n\nArguments\n\nupdates...: One or more update_struct objects (e.g., created by setup_de_update, setup_snooker_update, setup_subspace_sampling or your own custom sampler).\n\nKeyword Arguments\n\nw: A vector of weights corresponding to each update step. If nothing, updates are chosen with equal probability. Weights must be non-negative.\n\nExamples\n\n# only snooker updates\njulia> setup_sampler_scheme(setup_snooker_update())\n\n# DE and Snooker\njulia> setup_sampler_scheme(setup_snooker_update(), setup_de_update())\n\n# With weights, snookers 10% of the time\njulia> setup_sampler_scheme(setup_snooker_update(), setup_de_update(), w = [0.9, 0.1])\n\n\n\n\n\n","category":"function"},{"location":"#DEMetropolis.composite_sampler","page":"DEMetropolis Documentation","title":"DEMetropolis.composite_sampler","text":"Run a composite MCMC sampler for a fixed number of iterations.\n\nFor sampling with your own sampling scheme from setup_sampling_scheme\n\nArguments\n\nld: The log-density function to sample from, intended to be a LogDensityProblem.\nn_its: The desired number of samples per chain.\nn_chains: The number of chains to run.\nmemory: Boolean indicating whether to sample from historic values instead sampling from current chains.\ninitial_state: An array containing the initial states for the chains and the initial population if memory=true.\nsampler_scheme: A sampler_scheme_struct defining the update steps to use.\n\nKeyword Arguments\n\nthin: Thinning interval for storing samples. Defaults to 1. If using memory this also effects which samples are added to the memory.\nsave_burnt: Boolean indicating whether to save burn-in samples. Defaults to false. Does not save thinned samples\nrng: Random number generator. Defaults to default_rng().\nn_burnin: Number of burn-in iterations. Defaults to n_its * 5. Any adaptions occur over this period.\nparallel: Boolean indicating whether to run chains in parallel using multithreading. Defaults to false.\ndiagnostic_checks: A vector of diagnostic_check_struct to run during burn-in. Defaults to nothing.\ncheck_epochs: Splits n_burnin into check_epochs + 1 epochs and applies the diagnostic checks at the end of each epoch, other than the final epoch. Defaults to 1.\n\nReturns\n\nA named tuple containing the samples, sampler scheme, and potentially burn-in samples.\n\nExample\n\n# DE and Snooker sample scheme with memory\njulia> composite_sampler(\n    ld, 1000, 10, true, initial_state, setup_sampler_scheme(setup_snooker_update(), setup_de_update())\n)\n\nSee also deMC, deMCzs, DREAMz.\n\n\n\n\n\nRun a composite MCMC sampler until a stopping criterion is met.\n\nFor sampling with your own sampling scheme from setup_sampling_scheme.\n\nArguments\n\nld: The log-density function to sample from, intended to be a LogDensityProblem.\nepoch_size: The number of saved iterations per chain per epoch.\nn_chains: The number of chains to run.\nmemory: Boolean indicating whether to sample from historic values instead sampling from current chains.\ninitial_state: An array containing the initial states for the chains and the initial population if memory==true.\nsampler_scheme: A sampler_scheme_struct defining the update steps to use.\nstopping_criteria: A stopping_criteria_struct defining when to stop sampling.\n\nKeyword Arguments\n\nthin: Thinning interval for storing samples. Defaults to 1. If using memory this also effects which samples are added to the memory.\nsave_burnt: Boolean indicating whether to save burn-in samples. Defaults to false. Does not save thinned samples.\nrng: Random number generator. Defaults to default_rng().\nwarmup_epochs: Number of warm-up epochs before we begin checking the stopping criteria. Defaults to 5. Samples from these epochs won't be included in the final sample. Sampler adaptation only occurs in this period.\nparallel: Boolean indicating whether to run chains in parallel using multithreading. Defaults to false.\nepoch_limit: Maximum number of sampling epochs to run. Defaults to 20.\ndiagnostic_checks: A vector of diagnostic_check_struct to run during warm-up. Defaults to nothing.\n\nReturns\n\nA named tuple containing the samples, sampler scheme, and potentially burn-in samples.\n\nExample\n\n# DE and Snooker sample scheme with memory until Rhat ≤ 1.05\njulia> composite_sampler(\n    ld, 1000, 10, true, initial_state, setup_sampler_scheme(setup_snooker_update(), setup_de_update()), R̂_stopping_criteria(1.05)\n)\n\nSee also deMC, deMCzs, DREAMz.\n\n\n\n\n\n","category":"function"},{"location":"#Proposal-Distributions","page":"DEMetropolis Documentation","title":"Proposal Distributions","text":"","category":"section"},{"location":"#DEMetropolis.setup_de_update","page":"DEMetropolis Documentation","title":"DEMetropolis.setup_de_update","text":"Set up a Differential Evolution (DE) update step.\n\nSee doi.org/10.1007/s11222-006-8769-1 for more information.\n\nArguments\n\nld: The log-density function (used to determine dimension if γ is not provided).\n\nKeyword Arguments\n\nγ: The scaling factor for the difference vector. Can be a Real, a Distributions.UnivariateDistribution, or nothing. If nothing, it defaults based on deterministic_γ and the problem dimension.\nβ: Distribution for the small noise term added to the proposal. Defaults to Uniform(-1e-4, 1e-4).\ndeterministic_γ: If true and γ is nothing, sets γ to the theoretically optimal 2.38 / sqrt(2 * dim). If false, sets γ to Uniform(0.8, 1.2). Defaults to true.\n\nExample\n\njulia> setup_de_update(ld; β = Normal(0.0, 0.01))\n\nSee also setup_snooker_update, setup_subspace_sampling.\n\n\n\n\n\n","category":"function"},{"location":"#DEMetropolis.setup_snooker_update","page":"DEMetropolis Documentation","title":"DEMetropolis.setup_snooker_update","text":"Set up a Snooker update step.\n\nSee doi.org/10.1007/s11222-008-9104-9 for more information.\n\nKeyword Arguments\n\nγ: The scaling factor for the projection. Can be a Real, a Distributions.UnivariateDistribution, or nothing. If nothing, it defaults based on deterministic_γ.\ndeterministic_γ: If true and γ is nothing, sets γ to the theoretically optimal 2.38 / sqrt(2). If false, sets γ to Uniform(0.8, 1.2). Defaults to true.\n\nExample\n\njulia> setup_snooker_update(γ = Uniform(0.1, 2.0))\n\nSee also setup_de_update, setup_subspace_sampling.\n\n\n\n\n\n","category":"function"},{"location":"#DEMetropolis.setup_subspace_sampling","page":"DEMetropolis Documentation","title":"DEMetropolis.setup_subspace_sampling","text":"Set up a Subspace Sampling (DREAM-like) update step.\n\nSee doi.org/10.1515/IJNSNS.2009.10.3.273 for more information.\n\nKeyword Arguments\n\nγ: Fixed scaling factor for the difference vector sum. If nothing (default), uses 2.38 / sqrt(2 * δ * d) where d is the number of updated dimensions. If a Real is provided, uses that fixed value.\ncr: Crossover probability. Can be a Real (fixed probability), nothing (adaptive probability using n_cr values), or a Distributions.UnivariateDistribution. Defaults to nothing.\nn_cr: Number of crossover probabilities to adapt between if cr is nothing. Defaults to 3.\nδ: Number of difference vectors to add. Can be an Integer or a Distributions.DiscreteUnivariateDistribution. Defaults to DiscreteUniform(1, 3).\nϵ: Distribution for small noise added to the proposal in the selected subspace. Defaults to Uniform(-1e-4, 1e-4).\ne: Distribution for multiplicative noise (e + 1) applied to the difference vector sum. Defaults to Normal(0.0, 1e-2).\n\nExample\n\njulia> setup_subspace_sampling(cr = Beta(1, 2))\n\nSee also setup_de_update, setup_snooker_update.\n\n\n\n\n\n","category":"function"},{"location":"#Stopping-Criteria","page":"DEMetropolis Documentation","title":"Stopping Criteria","text":"","category":"section"},{"location":"#DEMetropolis.R̂_stopping_criteria","page":"DEMetropolis Documentation","title":"DEMetropolis.R̂_stopping_criteria","text":"Create a stopping criterion based on the rank Gelman-Rubin diagnostic (R̂). Sampling stops when the R̂ value for all parameters is below maximum_R̂.\n\nArguments\n\nmaximum_R̂: The maximum acceptable R̂ value. Defaults to 1.2.\n\nSee also MCMCDiagnosticTools.rhat.\n\n\n\n\n\n","category":"type"},{"location":"#Diagnostics-Checks-with-Resampling","page":"DEMetropolis Documentation","title":"Diagnostics Checks with Resampling","text":"","category":"section"},{"location":"#DEMetropolis.ld_check","page":"DEMetropolis Documentation","title":"DEMetropolis.ld_check","text":"Create a diagnostic check that identifies outlier chains based on their mean log-density (of the last 50% of the chain) during burn-in/warm-up. Outlier chains (those with mean log-density below Q1 - 2*IQR) are reset to the state of the chain with the highest mean log-density.\n\nSee: Vrugt 2009 doi.org/10.1515/IJNSNS.2009.10.3.273\n\nSee also acceptance_check.\n\n\n\n\n\n","category":"type"},{"location":"#DEMetropolis.acceptance_check","page":"DEMetropolis Documentation","title":"DEMetropolis.acceptance_check","text":"Create a diagnostic check that identifies poorly mixing chains based on their acceptance rate (of the last 50% of the chain) during burn-in/warm-up. Chains with acceptance rates below min_acceptance and significantly lower than others (based on log-acceptance rate IQR) are reset to the state of the chain closest to the target_acceptance rate.\n\nArguments\n\nmin_acceptance: The minimum acceptable acceptance rate. Defaults to 0.1.\ntarget_acceptance: The target acceptance rate used to select the best chain for resetting outliers. Defaults to 0.24.\n\nSee also ld_check.\n\n\n\n\n\n","category":"type"},{"location":"#Index","page":"DEMetropolis Documentation","title":"Index","text":"","category":"section"},{"location":"","page":"DEMetropolis Documentation","title":"DEMetropolis Documentation","text":"","category":"page"},{"location":"tutorial/#Sampling-from-multimodal-distributions","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"","category":"section"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"Let say you have a multimodal distribution, for example a mixture of two Gaussians. DEMetropolis implements differential evolution MCMC samplers (including deMC-zs and DREAMz) that are designed to sample from such distributions efficiently. Roughly these samplers work by generating new proposals based on many separate chains (or a history of sampled chains). In theory this allows the sampler to easily jump between modes of the distribution.","category":"page"},{"location":"tutorial/#Multimodal-Distributions","page":"Sampling from multimodal distributions","title":"Multimodal Distributions","text":"","category":"section"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"First we need to implement a multimodal distribution. We'll use a mixture of three Gaussians for one parameter and two LogNormal distributions for another, making this a 2D distribution. We can easily implement this using the Distributions package, which underpins most of the functionality in DEMetropolis.","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"using Distributions\n\nα_mixed_dist = MixtureModel([\n    Normal(-5.0, 0.5),\n    Normal(0.0, 0.5),\n    Normal(5.0, 0.5)\n], [1/4, 1/4, 1/2]);\n\nβ_mixed_dist = MixtureModel([\n    LogNormal(-0.5, 0.5),\n    LogNormal(1.75, 0.25)\n], [1/6, 5/6]);\n\nfunction multimodal_ld(θ)\n    (; α, β) = θ\n    logpdf(α_mixed_dist, α) +\n        logpdf(β_mixed_dist, β)\nend","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"We can also transform our log density function, so we can provide real-valued inputs. This is much easier to work with.","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"using TransformedLogDensities, TransformVariables\ntransformation = as((α = asℝ, β = asℝ₊))\ntransformed_ld = TransformedLogDensity(transformation, multimodal_ld)","category":"page"},{"location":"tutorial/#Sampling-with-DEMetropolis","page":"Sampling from multimodal distributions","title":"Sampling with DEMetropolis","text":"","category":"section"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"Now let's use DEMetropolis to sample from this multimodal distribution. Here we use the DREAMz sampler, which is well-suited for exploring complex, multimodal spaces. We increase the number of chains to allow the sampler to explore the distribution more effectively.","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"using DEMetropolis\n\ndreamz = DREAMz(transformed_ld, 10000; thin = 2, n_chains = 5);","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"Other implementations of the differential evolution MCMC algorithm are available in DEMetropolis.jl, such as deMC and deMCzs, which can be used similarly.","category":"page"},{"location":"tutorial/#Custom-Scheme","page":"Sampling from multimodal distributions","title":"Custom Scheme","text":"","category":"section"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"DREAMz can be further customized. For example, we could include snooker updates alongside the DREAMz-like subspace sampling.","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"You can also modify aspects of the implemented sampling, for example tell DREAMz to use not memory-based sampling with DREAMz(..., memory = false), or you can define your own sampler scheme for more control over the sampling process.","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"using DEMetropolis, LogDensityProblems\n\nlow_chains_sampler = setup_sampler_scheme(\n    setup_subspace_sampling(), # a DREAM-like sampler that uses subspace sampling\n    setup_snooker_update(deterministic_γ = false); # a snooker update for better exploration\n    w = [0.8, 0.2] # only use snooker 20% of the time\n);\n\ninitial_state = randn(100, LogDensityProblems.dimension(transformed_ld));\n\ncustom = composite_sampler(\n    transformed_ld, 10000, 5, true, initial_state, low_chains_sampler, R̂_stopping_criteria(1.05);\n    diagnostic_checks = [ld_check()]\n);","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"You can also define your own samplers for more specialized use cases.","category":"page"},{"location":"tutorial/#Interpreting-Results","page":"Sampling from multimodal distributions","title":"Interpreting Results","text":"","category":"section"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"After running the sampler, you will have a collection of samples from the target distribution. These samples can be used to estimate summary statistics, credible intervals, and to assess the quality of your sampling.","category":"page"},{"location":"tutorial/#Assessing-Sampler-Performance:-ESS-and-R-hat","page":"Sampling from multimodal distributions","title":"Assessing Sampler Performance: ESS and R-hat","text":"","category":"section"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"To evaluate how well your sampler is performing, you can compute the effective sample size (ESS) and the R-hat diagnostic. These metrics help you determine if your chains have mixed well and if your estimates are reliable.","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"Effective Sample Size (ESS): This measures the number of independent samples your chains are equivalent to. Higher ESS values indicate more reliable estimates.\nR-hat Diagnostic: Also known as the Gelman-Rubin statistic, R-hat compares the variance within each chain to the variance between chains. Values close to 1 suggest good mixing and convergence; values much greater than 1 indicate potential problems.","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"Below is an example of how to compute these diagnostics for two DEMetropolis samplers, dreamz and custom, using MCMCChains:","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"using Statistics, MCMCDiagnosticTools\n\nsamplers = [dreamz, custom]\nsampler_names = [\"DREAMz\", \"Custom Sampler\"]\n\nfor (sampler, name) in zip(samplers, sampler_names)\n    samples = sampler.samples  # shape: (iterations, chains, parameters)\n    ess_val = ess(samples)./size(samples, 1)\n    rhat_val = maximum(rhat(samples))\n    println(\"$name diagnostics:\")\n    println(\"  ESS per iteration: $ess_val\")\n    println(\"  R-hat: $rhat_val\\n\")\nend","category":"page"},{"location":"tutorial/#Summarizing-Posterior-Samples","page":"Sampling from multimodal distributions","title":"Summarizing Posterior Samples","text":"","category":"section"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"Once you have confirmed good mixing and convergence, you can summarize your posterior samples. For each parameter, you may want to compute the median and a credible interval (such as the 90% interval):","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"# Example: summarize the DREAMz sampler's posterior\nsamples = dreamz.samples\nn_params = size(samples, 3)\n\n# Flatten the samples across all chains and iterations for each parameter\nflat_samples = [vec(samples[:, :, param]) for param in 1:n_params]\n\nfor (i, param_samples) in enumerate(flat_samples)\n    med = median(param_samples)\n    q05, q95 = quantile(param_samples, [0.05, 0.95])\n    println(\"Parameter $i: median = $med, 90% CI = ($q05, $q95)\")\nend","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"This will print the median and 90% credible interval for each parameter, giving you a summary of the posterior distribution.","category":"page"},{"location":"tutorial/","page":"Sampling from multimodal distributions","title":"Sampling from multimodal distributions","text":"For more details, see the DEMetropolis Documentation and the Customizing your sampler section. For general Julia documentation and best practices, refer to the Julia documentation manual.","category":"page"}]
}
